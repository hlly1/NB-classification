{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1 -- Naive Bayes and K-Nearest Neighbour for Predicting Stroke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import metrics\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#All functions that will be used\n",
    "def preprocess(csv):\n",
    "    return pd.read_csv(csv)\n",
    "\n",
    "def split_data(table):\n",
    "    #30% for test set, 70% for train set\n",
    "    # random seed is 7, to keep the only one result in this assignment\n",
    "    return train_test_split(table.iloc[:,: 10], table.iloc[:,-1],test_size=0.3, random_state=7) \n",
    "\n",
    "def train(x_train, y_train):\n",
    "    train_set = pd.concat([x_train, y_train], axis = 1)\n",
    "    p_dict = {}\n",
    "    labels = x_train.columns\n",
    "    y_instances = y_train.value_counts().items()\n",
    "    \n",
    "    #How many features for each label, otherwise work_type would give wierd error when stroke is 1, so define it at first\n",
    "    features = {}\n",
    "    for j in labels:\n",
    "        features[j] = x_train[j].value_counts().index\n",
    "    \n",
    "    aset = train_set.groupby(y_train.values)\n",
    "\n",
    "    for y_item in y_instances:\n",
    "        # prob for each label when stroke = 0 and 1\n",
    "        p_dict[y_item[0]] = {}\n",
    "        \n",
    "    for temp in aset:\n",
    "        for af in labels:\n",
    "            each_p = {}\n",
    "            instance_f = temp[1][af].value_counts()\n",
    "            #work_type class is 3 when stroke is 1, so add 0 to match the length\n",
    "            for af_type in features[af]:\n",
    "                if not(af_type in instance_f):\n",
    "                    instance_f[af_type] = 0\n",
    "                    \n",
    "            for i_f_item in instance_f.items():\n",
    "                #Laplace smoothing, numerator is added with alpha(normally 1) and denominator becomes M*1+count.\n",
    "                p_f = (i_f_item[1] + 1) / (len(temp[1][af]) + len(features[af]))\n",
    "                each_p[i_f_item[0]] = p_f\n",
    "                \n",
    "            p_dict[temp[0]][af] = each_p\n",
    "    return p_dict\n",
    "   \n",
    "def predict(adict, x_test, y_train):\n",
    "    #get the probabilities of storke 0 and 1\n",
    "    py=getYprob(y_train)\n",
    "    prelist=[]\n",
    "    #for each instance in test set\n",
    "    for test_item in range(len(x_test)):\n",
    "        item = x_test.iloc[test_item]\n",
    "        mrate=0\n",
    "        y_c = \"\"\n",
    "        #at the second dict which contains value\n",
    "        for aclass in adict.items():\n",
    "            # for stroke 0 or 1\n",
    "            for i in range(len(py)):\n",
    "                # for each data in a label\n",
    "                for a in aclass[1].items():\n",
    "                    #calculate rate\n",
    "                    r = py[i] * a[1].get(item[a[0]])\n",
    "                # situation1: mrate is 0 at the beginning\n",
    "                if mrate == 0:\n",
    "                    mrate=r\n",
    "                    y_c = aclass[0]\n",
    "                # situation2: when mrate is not 1\n",
    "                if r > mrate:\n",
    "                    mrate=r\n",
    "                    y_c = aclass[0]\n",
    "        prelist.append(y_c)\n",
    "    \n",
    "    return prelist\n",
    "\n",
    "def evaluate(prelist, y_test):\n",
    "    return metrics.accuracy_score(y_test.values, prelist), metrics.f1_score(y_test.values, prelist), metrics.recall_score(y_test.values, prelist), metrics.precision_score(y_test.values, prelist)\n",
    "    \n",
    "def replace_to_number(table):\n",
    "    l1st = ['gender', 'ever_married', 'work_type', 'Residence_type', 'smoking_status']\n",
    "    for item in l1st:\n",
    "        el = np.unique(table[item])\n",
    "        lens = len(el)\n",
    "        for i in range(lens):\n",
    "            table[item].replace(el[i], i, inplace=True)\n",
    "    return table\n",
    "\n",
    "def discrete(table):\n",
    "    for a_label in ['avg_glucose_level','bmi','age']:\n",
    "        table[a_label] = pd.cut(table[a_label], 10, labels=range(10))\n",
    "    return table\n",
    "\n",
    "def getYprob(y):\n",
    "    p_y = []\n",
    "    for y_one in y.value_counts().sort_index(ascending=True).items():\n",
    "        p_y.append(y_one[1]/len(y))\n",
    "    return p_y\n",
    "\n",
    "def knn(x_train, y_train, kn):\n",
    "    classifier = KNeighborsClassifier(n_neighbors = kn)\n",
    "    classifier.fit(x_train, y_train)\n",
    "    return classifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4>**a). Explore the data and summarise different aspects of the data. Can you see any interesting\n",
    "characteristic in features, classes or categories? What is the main issue with the data?\n",
    "Considering the issue, how would the Naive Bayes classifier work on this data? Discuss\n",
    "your answer based on the Naive Bayesâ€™ formulation (3 marks)**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_glucose_level</th>\n",
       "      <th>bmi</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>ever_married</th>\n",
       "      <th>work_type</th>\n",
       "      <th>Residence_type</th>\n",
       "      <th>smoking_status</th>\n",
       "      <th>stroke</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>137.45</td>\n",
       "      <td>26.0</td>\n",
       "      <td>53</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Self-employed</td>\n",
       "      <td>Rural</td>\n",
       "      <td>smokes</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>56.85</td>\n",
       "      <td>24.4</td>\n",
       "      <td>44</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Rural</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>87.79</td>\n",
       "      <td>41.1</td>\n",
       "      <td>49</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>Private</td>\n",
       "      <td>Urban</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>94.82</td>\n",
       "      <td>22.9</td>\n",
       "      <td>28</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>Private</td>\n",
       "      <td>Urban</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>96.80</td>\n",
       "      <td>29.6</td>\n",
       "      <td>73</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Urban</td>\n",
       "      <td>formerly smoked</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2735</th>\n",
       "      <td>88.29</td>\n",
       "      <td>36.0</td>\n",
       "      <td>79</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Self-employed</td>\n",
       "      <td>Urban</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2736</th>\n",
       "      <td>93.38</td>\n",
       "      <td>26.7</td>\n",
       "      <td>76</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Self-employed</td>\n",
       "      <td>Rural</td>\n",
       "      <td>formerly smoked</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2737</th>\n",
       "      <td>83.27</td>\n",
       "      <td>32.9</td>\n",
       "      <td>56</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Rural</td>\n",
       "      <td>smokes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2738</th>\n",
       "      <td>75.91</td>\n",
       "      <td>26.7</td>\n",
       "      <td>80</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Self-employed</td>\n",
       "      <td>Urban</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2739</th>\n",
       "      <td>77.97</td>\n",
       "      <td>31.5</td>\n",
       "      <td>62</td>\n",
       "      <td>Male</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Rural</td>\n",
       "      <td>formerly smoked</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2740 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      avg_glucose_level   bmi  age  gender  hypertension  heart_disease  \\\n",
       "0                137.45  26.0   53    Male             0              0   \n",
       "1                 56.85  24.4   44  Female             0              0   \n",
       "2                 87.79  41.1   49  Female             0              0   \n",
       "3                 94.82  22.9   28  Female             0              0   \n",
       "4                 96.80  29.6   73    Male             0              0   \n",
       "...                 ...   ...  ...     ...           ...            ...   \n",
       "2735              88.29  36.0   79    Male             0              1   \n",
       "2736              93.38  26.7   76    Male             0              0   \n",
       "2737              83.27  32.9   56  Female             0              0   \n",
       "2738              75.91  26.7   80  Female             0              0   \n",
       "2739              77.97  31.5   62    Male             1              1   \n",
       "\n",
       "     ever_married      work_type Residence_type   smoking_status  stroke  \n",
       "0             Yes  Self-employed          Rural           smokes       0  \n",
       "1             Yes        Private          Rural     never smoked       0  \n",
       "2              No        Private          Urban     never smoked       0  \n",
       "3              No        Private          Urban     never smoked       0  \n",
       "4             Yes        Private          Urban  formerly smoked       0  \n",
       "...           ...            ...            ...              ...     ...  \n",
       "2735          Yes  Self-employed          Urban     never smoked       1  \n",
       "2736          Yes  Self-employed          Rural  formerly smoked       1  \n",
       "2737          Yes        Private          Rural           smokes       1  \n",
       "2738          Yes  Self-employed          Urban     never smoked       1  \n",
       "2739          Yes        Private          Rural  formerly smoked       1  \n",
       "\n",
       "[2740 rows x 11 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table = preprocess(\"stroke_update.csv\")\n",
    "age_row = table.iloc[:, 2]\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Summarise:**\n",
    "\n",
    "<font size=3>\n",
    "Overall there are 2740 instances and 11 attributes. The avg_glucose_level, bmi and age are numeric while others are not. The avg_glucose_level, bmi are continuous while others are discrete. Some features are in letters which makes code difficult to do analysis(e.g. ever_married, work_type etc) but some other features are in number(e.g. hypertension and heart_disease). The table is not randomly ordered for stroke starts from (stroke=0)  then followed by (stroke=1).\n",
    "</font>\n",
    "\n",
    "**Interesting characteristic:**\n",
    "\n",
    "<font size=3>\n",
    "From 0 to 2734, the stroke are all 0 and from 2735 to the end, the strokes are all 1. The test set and training set both require that each instance is randomly chosen.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_glucose_level</th>\n",
       "      <th>bmi</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>ever_married</th>\n",
       "      <th>work_type</th>\n",
       "      <th>Residence_type</th>\n",
       "      <th>smoking_status</th>\n",
       "      <th>stroke</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>avg_glucose_level</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.222221</td>\n",
       "      <td>0.267942</td>\n",
       "      <td>0.048000</td>\n",
       "      <td>0.153631</td>\n",
       "      <td>0.199533</td>\n",
       "      <td>0.140880</td>\n",
       "      <td>0.027007</td>\n",
       "      <td>-0.010321</td>\n",
       "      <td>-0.075984</td>\n",
       "      <td>0.195651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bmi</th>\n",
       "      <td>0.222221</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.073568</td>\n",
       "      <td>0.015591</td>\n",
       "      <td>0.120742</td>\n",
       "      <td>0.015180</td>\n",
       "      <td>0.130180</td>\n",
       "      <td>-0.058395</td>\n",
       "      <td>0.015028</td>\n",
       "      <td>-0.035732</td>\n",
       "      <td>-0.010339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>0.267942</td>\n",
       "      <td>0.073568</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.062799</td>\n",
       "      <td>0.299846</td>\n",
       "      <td>0.261760</td>\n",
       "      <td>0.525890</td>\n",
       "      <td>0.033891</td>\n",
       "      <td>0.016144</td>\n",
       "      <td>-0.188859</td>\n",
       "      <td>0.431107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gender</th>\n",
       "      <td>0.048000</td>\n",
       "      <td>0.015591</td>\n",
       "      <td>0.062799</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.039282</td>\n",
       "      <td>0.102391</td>\n",
       "      <td>0.051499</td>\n",
       "      <td>0.038683</td>\n",
       "      <td>0.021190</td>\n",
       "      <td>-0.030364</td>\n",
       "      <td>0.035096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hypertension</th>\n",
       "      <td>0.153631</td>\n",
       "      <td>0.120742</td>\n",
       "      <td>0.299846</td>\n",
       "      <td>0.039282</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.127824</td>\n",
       "      <td>0.141752</td>\n",
       "      <td>0.022000</td>\n",
       "      <td>-0.000873</td>\n",
       "      <td>-0.053598</td>\n",
       "      <td>0.192728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>heart_disease</th>\n",
       "      <td>0.199533</td>\n",
       "      <td>0.015180</td>\n",
       "      <td>0.261760</td>\n",
       "      <td>0.102391</td>\n",
       "      <td>0.127824</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.100569</td>\n",
       "      <td>0.006069</td>\n",
       "      <td>-0.006143</td>\n",
       "      <td>-0.035016</td>\n",
       "      <td>0.256132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ever_married</th>\n",
       "      <td>0.140880</td>\n",
       "      <td>0.130180</td>\n",
       "      <td>0.525890</td>\n",
       "      <td>0.051499</td>\n",
       "      <td>0.141752</td>\n",
       "      <td>0.100569</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.058714</td>\n",
       "      <td>0.027941</td>\n",
       "      <td>-0.059003</td>\n",
       "      <td>0.158306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>work_type</th>\n",
       "      <td>0.027007</td>\n",
       "      <td>-0.058395</td>\n",
       "      <td>0.033891</td>\n",
       "      <td>0.038683</td>\n",
       "      <td>0.022000</td>\n",
       "      <td>0.006069</td>\n",
       "      <td>-0.058714</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.006563</td>\n",
       "      <td>-0.044576</td>\n",
       "      <td>0.052052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Residence_type</th>\n",
       "      <td>-0.010321</td>\n",
       "      <td>0.015028</td>\n",
       "      <td>0.016144</td>\n",
       "      <td>0.021190</td>\n",
       "      <td>-0.000873</td>\n",
       "      <td>-0.006143</td>\n",
       "      <td>0.027941</td>\n",
       "      <td>-0.006563</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.032341</td>\n",
       "      <td>0.003285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smoking_status</th>\n",
       "      <td>-0.075984</td>\n",
       "      <td>-0.035732</td>\n",
       "      <td>-0.188859</td>\n",
       "      <td>-0.030364</td>\n",
       "      <td>-0.053598</td>\n",
       "      <td>-0.035016</td>\n",
       "      <td>-0.059003</td>\n",
       "      <td>-0.044576</td>\n",
       "      <td>-0.032341</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.057498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stroke</th>\n",
       "      <td>0.195651</td>\n",
       "      <td>-0.010339</td>\n",
       "      <td>0.431107</td>\n",
       "      <td>0.035096</td>\n",
       "      <td>0.192728</td>\n",
       "      <td>0.256132</td>\n",
       "      <td>0.158306</td>\n",
       "      <td>0.052052</td>\n",
       "      <td>0.003285</td>\n",
       "      <td>-0.057498</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   avg_glucose_level       bmi       age    gender  \\\n",
       "avg_glucose_level           1.000000  0.222221  0.267942  0.048000   \n",
       "bmi                         0.222221  1.000000  0.073568  0.015591   \n",
       "age                         0.267942  0.073568  1.000000  0.062799   \n",
       "gender                      0.048000  0.015591  0.062799  1.000000   \n",
       "hypertension                0.153631  0.120742  0.299846  0.039282   \n",
       "heart_disease               0.199533  0.015180  0.261760  0.102391   \n",
       "ever_married                0.140880  0.130180  0.525890  0.051499   \n",
       "work_type                   0.027007 -0.058395  0.033891  0.038683   \n",
       "Residence_type             -0.010321  0.015028  0.016144  0.021190   \n",
       "smoking_status             -0.075984 -0.035732 -0.188859 -0.030364   \n",
       "stroke                      0.195651 -0.010339  0.431107  0.035096   \n",
       "\n",
       "                   hypertension  heart_disease  ever_married  work_type  \\\n",
       "avg_glucose_level      0.153631       0.199533      0.140880   0.027007   \n",
       "bmi                    0.120742       0.015180      0.130180  -0.058395   \n",
       "age                    0.299846       0.261760      0.525890   0.033891   \n",
       "gender                 0.039282       0.102391      0.051499   0.038683   \n",
       "hypertension           1.000000       0.127824      0.141752   0.022000   \n",
       "heart_disease          0.127824       1.000000      0.100569   0.006069   \n",
       "ever_married           0.141752       0.100569      1.000000  -0.058714   \n",
       "work_type              0.022000       0.006069     -0.058714   1.000000   \n",
       "Residence_type        -0.000873      -0.006143      0.027941  -0.006563   \n",
       "smoking_status        -0.053598      -0.035016     -0.059003  -0.044576   \n",
       "stroke                 0.192728       0.256132      0.158306   0.052052   \n",
       "\n",
       "                   Residence_type  smoking_status    stroke  \n",
       "avg_glucose_level       -0.010321       -0.075984  0.195651  \n",
       "bmi                      0.015028       -0.035732 -0.010339  \n",
       "age                      0.016144       -0.188859  0.431107  \n",
       "gender                   0.021190       -0.030364  0.035096  \n",
       "hypertension            -0.000873       -0.053598  0.192728  \n",
       "heart_disease           -0.006143       -0.035016  0.256132  \n",
       "ever_married             0.027941       -0.059003  0.158306  \n",
       "work_type               -0.006563       -0.044576  0.052052  \n",
       "Residence_type           1.000000       -0.032341  0.003285  \n",
       "smoking_status          -0.032341        1.000000 -0.057498  \n",
       "stroke                   0.003285       -0.057498  1.000000  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_table = replace_to_number(table)\n",
    "new_table.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Main Issue**\n",
    "\n",
    "<font size=3>\n",
    "According to the output above, some results are high which means they have correlation.Based on Naive Bayers, P(x1, x2, ..., xm |y)P(y) â‰ˆ P(x1|y)P(x2|y)...P(xm|y)P(y), under the condition of class y, it is assumed that the features are independent. In this case, some features have strong correlation(e.g. age and ever_married) and the formular equation would not hold anymore. So there is a good way to handle this data set that is delete the data that has strong correlation or join them together.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4>**b). Is accuracy an appropriate metric to evaluate the models created for this data? Justify\n",
    "your answer. Explain which metric(s) would be more appropriate, and contrast their utility\n",
    "against accuracy. [no programming required] (2 marks)**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3>\n",
    "No\n",
    "\n",
    "Only accuracy is not enough to evaluate the probaility of getting stroke for a person. Some people who have stroke would be diagnosed with no stroke and it would cause a serious consequence. There is no reason to gurantee that our data set is disaggregated. So accuracy is not full-scale. Precision and recall and F1-score would be more appropriate. Accuracy is only the frequence of the classifer is correct. Precision is how many people that are identified as stroke by classifer is actually identified as stroke. Recall is how many people are figured out with stroke in all the people that actually have stroke or not. F1-score is an additional opinion to evaluate the precision and recall better.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4>**a). Explain the independence assumption underlying Naive Bayes. What are the advantages\n",
    "and disadvantages of this assumption? Elaborate your answers using the features of the\n",
    "provided data. [no programming required] (1 mark)**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explain:**\n",
    "\n",
    "<font size=3>\n",
    "The independence assumption is that assuming the features are strongly independent with each other. In the real life, that is not always true, so it is called \"naive\".\n",
    "</font>\n",
    "\n",
    "**Advantage:**\n",
    "\n",
    "<font size=3>\n",
    "It is easy to build and estimate model, for example, work_type has 5 types and ever_married has 2 types, the overall possibailities are too many and it makes joint probabilities really hard to calculate and there are also many 0 probabilities in it. So \"naive\" could help us solve the problems and it works well. \n",
    "</font>\n",
    "\n",
    "**Disadvantage:**\n",
    "\n",
    "<font size=3>\n",
    "In real life, the \"naive\" assumption is not always true. For example, according to the output of \"new_table.corr()\" above, when age is 1, ever_marriged is 0.5258 which means they have strong correlation. But \"naive\" assumption ignore both weak(e.g. BMI=0.2 and age=1) and strong correlation and it is unreasonable.So it makes Naive Bayers naturally has an error.\n",
    "</font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4>**b). Implement the Naive Bayes classifier. You need to decide how you are going to apply\n",
    "Naive Bayes for nominal and numeric attributes. You can combine both Gaussian and\n",
    "Categorical Naive Bayes (option 1) or just using Categorical Naive Bayes (option 2). Explain\n",
    "your decision.\n",
    "For Categorical Naive Bayes, you can choose either epsilon or Laplace smoothing\n",
    "for this calculation. Evaluate the classifier using accuracy and appropriate metric(s) on test\n",
    "data. Explain your observations on how the classifiers have performed based on the metric(\n",
    "s). Discuss the performance of the classifiers in comparison with the Zero-R baseline.\n",
    "(4 marks)**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Only using Categotical Naive Bayers**\n",
    "\n",
    "<font size=3>\n",
    "According to the data below, the data is not suitable for Gaussian distribution. Because some features has a high maximum value and low minium value while the difference between mean with 2 values are high(e.g. bmi max: 70.3, bmi min: 11.0, bmi mean:  29.992043795620443). Using Categotical Naive Bayers can process data easier and it is a suitable way to do it.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2    1742\n",
      "3     577\n",
      "0     366\n",
      "4      49\n",
      "1       6\n",
      "Name: work_type, dtype: int64\n",
      "bmi max:  70.3\n",
      "bmi min:  11.0\n",
      "bmi mean:  29.992043795620443\n",
      "agl max:  271.74\n",
      "agl min:  55.01\n",
      "agl mean:  111.3860401459854\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_glucose_level</th>\n",
       "      <th>bmi</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>ever_married</th>\n",
       "      <th>work_type</th>\n",
       "      <th>Residence_type</th>\n",
       "      <th>smoking_status</th>\n",
       "      <th>stroke</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>137.45</td>\n",
       "      <td>26.0</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>56.85</td>\n",
       "      <td>24.4</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>87.79</td>\n",
       "      <td>41.1</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>94.82</td>\n",
       "      <td>22.9</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>96.80</td>\n",
       "      <td>29.6</td>\n",
       "      <td>73</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2735</th>\n",
       "      <td>88.29</td>\n",
       "      <td>36.0</td>\n",
       "      <td>79</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2736</th>\n",
       "      <td>93.38</td>\n",
       "      <td>26.7</td>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2737</th>\n",
       "      <td>83.27</td>\n",
       "      <td>32.9</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2738</th>\n",
       "      <td>75.91</td>\n",
       "      <td>26.7</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2739</th>\n",
       "      <td>77.97</td>\n",
       "      <td>31.5</td>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2740 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      avg_glucose_level   bmi  age  gender  hypertension  heart_disease  \\\n",
       "0                137.45  26.0   53       1             0              0   \n",
       "1                 56.85  24.4   44       0             0              0   \n",
       "2                 87.79  41.1   49       0             0              0   \n",
       "3                 94.82  22.9   28       0             0              0   \n",
       "4                 96.80  29.6   73       1             0              0   \n",
       "...                 ...   ...  ...     ...           ...            ...   \n",
       "2735              88.29  36.0   79       1             0              1   \n",
       "2736              93.38  26.7   76       1             0              0   \n",
       "2737              83.27  32.9   56       0             0              0   \n",
       "2738              75.91  26.7   80       0             0              0   \n",
       "2739              77.97  31.5   62       1             1              1   \n",
       "\n",
       "      ever_married  work_type  Residence_type  smoking_status  stroke  \n",
       "0                1          3               0               2       0  \n",
       "1                1          2               0               1       0  \n",
       "2                0          2               1               1       0  \n",
       "3                0          2               1               1       0  \n",
       "4                1          2               1               0       0  \n",
       "...            ...        ...             ...             ...     ...  \n",
       "2735             1          3               1               1       1  \n",
       "2736             1          3               0               0       1  \n",
       "2737             1          2               0               2       1  \n",
       "2738             1          3               1               1       1  \n",
       "2739             1          2               0               0       1  \n",
       "\n",
       "[2740 rows x 11 columns]"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(table['work_type'].value_counts())\n",
    "print(\"bmi max: \", table['bmi'].max())\n",
    "print(\"bmi min: \", table['bmi'].min())\n",
    "print(\"bmi mean: \", table['bmi'].mean())\n",
    "print(\"agl max: \",table['avg_glucose_level'].max())\n",
    "print(\"agl min: \",table['avg_glucose_level'].min())\n",
    "print(\"agl mean: \",table['avg_glucose_level'].mean())\n",
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This part is for train()\n",
    "table = replace_to_number(preprocess(\"stroke_update.csv\"))\n",
    "x_train, x_test, y_train, y_test = split_data(table)\n",
    "discrete_x_train = discrete(x_train)\n",
    "train_dict = train(discrete_x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3>---------------data above for supporting the partial answer b)(the one at top)-----------------------------------------</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3>---------------data below for supporting the other partial answer b)(the one at bottom)-----------------------------------------</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    1210\n",
       "3     411\n",
       "0     261\n",
       "4      32\n",
       "1       4\n",
       "Name: work_type, dtype: int64"
      ]
     },
     "execution_count": 433,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train['work_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total num of test instance:  822\n",
      "CNB accuracy:  0.6581508515815085\n",
      "CNB F1-Score:  0.28498727735368956\n",
      "CNB recall:  0.32\n",
      "CNB precision:  0.25688073394495414\n"
     ]
    }
   ],
   "source": [
    "#This part is for predict()\n",
    "table = replace_to_number(preprocess(\"stroke_update.csv\"))\n",
    "x_train, x_test, y_train, y_test = split_data(table)\n",
    "discrete_x_train = discrete(x_train)\n",
    "train_dict = train(discrete_x_train, y_train)\n",
    "discrete_x_test = discrete(x_test)\n",
    "print(\"Total num of test instance: \",len(predict(train_dict, discrete_x_test, y_train)))\n",
    "#Each list represent the predict of one instance from all cases\n",
    "prelist = predict(train_dict, discrete_x_test, y_train)\n",
    "e = evaluate(prelist, y_test)\n",
    "print(\"CNB accuracy: \", e[0])\n",
    "print(\"CNB F1-Score: \", e[1])\n",
    "print(\"CNB recall: \", e[2])\n",
    "print(\"CNB precision: \", e[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    660\n",
      "1    162\n",
      "Name: stroke, dtype: int64\n",
      "Zero-R accuracy:  0.8029197080291971\n",
      "Zero-R F1-Score:  0.0\n",
      "Zero-R recall:  0.0\n",
      "Zero-R precision:  0.0\n"
     ]
    }
   ],
   "source": [
    "#Zero-R\n",
    "print(y_test.value_counts())\n",
    "zeroRlist=[0 for _ in range(len(x_test))]\n",
    "print(\"Zero-R accuracy: \",metrics.accuracy_score(y_test.values, zeroRlist))\n",
    "print(\"Zero-R F1-Score: \",metrics.f1_score(y_test.values, zeroRlist))\n",
    "print(\"Zero-R recall: \",metrics.recall_score(y_test.values, prelist))\n",
    "#precision is actually 0, using code will get warning\n",
    "print(\"Zero-R precision: \", 0.0)\n",
    "# print(metrics.precision_score(y_test.values, prelist))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations**\n",
    "\n",
    "<font size=3>\n",
    "In this case, aloungh the accuracy of CNB is very high, but it is not good enough as a metric. Because Zero-R also has a high accuracy while other metrics(e.g. precision, recall, F1-Score) are all 0. So the performance of accuracy is really bad. The combination of accuracy, precision, recall and F1-Score could perform better. In this case, CNB F1-score only has 66%, and the value of recall(30.4%), precision(24.30%) are also low. It means the performance of perdict is not good as we expect. But accuracy looks like all goes well.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4>**c). Explain the difference between epsilon and Laplace smoothing. [no programming\n",
    "required] (1 mark)**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3>In Laplace smoothing, numerator is added with alpha(normally 1) and denominator becomes M * alpha + count. But in epsilon smoothing, 0 is only replaced with as much small constant as it can to keep probabilities with the most minimal change and the distribution is kept all the time. In Laplace smoothing, if the instances is few, the change would be drastical while the change would be small if there are few instances.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4>**a) Implement the K-NN classifier, and find the optimal value for K. (1 mark)**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate from loop kn= 129 :  0.816301703163017\n",
      "evaluate from kn=129:  0.816301703163017\n"
     ]
    }
   ],
   "source": [
    "#find the optimal value for K from[0, 1000]\n",
    "knnlist=[]\n",
    "for i in range(1, 201):\n",
    "    knnlist.append(evaluate(knn(x_train, y_train, i).predict(x_test), y_test)[0])\n",
    "\n",
    "#Because the index starts from 0, to match kn, it should plus 1, index 0 represent accuracy in evaluate\n",
    "print(\"evaluate from loop kn=\",knnlist.index(max(knnlist))+1,\": \",max(knnlist))\n",
    "#Check if the evaluate of two kn are same or not, index 0 represent accuracy in evaluate\n",
    "print(\"evaluate from kn=129: \", evaluate(knn(x_train, y_train, 129).predict(x_test), y_test)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3>\n",
    "To sum up, according to the data above, the optimal value for K in [1,200] is 129.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4>**b) Based on the obtained value for K in question 4 (a), evaluate the classifier using accuracy\n",
    "and chosen metric(s) on test data. Explain your observations on how the classifiers have\n",
    "performed based on the metric(s). Discuss the performance of the classifiers in comparison\n",
    "with the Zero- R baseline. (2 marks)**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    660\n",
      "1    162\n",
      "Name: stroke, dtype: int64\n",
      "Zero-R accuracy:  0.8029197080291971\n",
      "Zero-R F1-Score:  0.0\n",
      "Zero-R recall:  0.0\n",
      "Zero-R precision:  0.0\n"
     ]
    }
   ],
   "source": [
    "#Zero-R\n",
    "print(y_test.value_counts())\n",
    "zeroRlist=[0 for _ in range(len(x_test))]\n",
    "print(\"Zero-R accuracy: \",metrics.accuracy_score(y_test.values, zeroRlist))\n",
    "print(\"Zero-R F1-Score: \",metrics.f1_score(y_test.values, zeroRlist))\n",
    "print(\"Zero-R recall: \",metrics.recall_score(y_test.values, prelist))\n",
    "#precision is actually 0, using code will get warning\n",
    "print(\"Zero-R precision: \", 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k-nn accuracy:  0.816301703163017\n",
      "k-nn F1-Score:  0.32888888888888884\n",
      "k-nn recall:  0.22839506172839505\n",
      "k-nn precision:  0.5873015873015873\n"
     ]
    }
   ],
   "source": [
    "e = evaluate(knn(x_train, y_train, 129).predict(x_test), y_test)\n",
    "print(\"k-nn accuracy: \", e[0])\n",
    "print(\"k-nn F1-Score: \", e[1])\n",
    "print(\"k-nn recall: \", e[2])\n",
    "print(\"k-nn precision: \", e[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation**\n",
    "\n",
    "<font size=3>\n",
    " The accuracy of K-NN and Zero-R is close(80.29% for 0-R and 81.63% for K-NN).<br>\n",
    " 58.73% people are predicted out in all people who have stroke. In 0-R, it's 0<br>\n",
    " 22.84% people have stroke out of people predicted out.In 0-R, it's 0<br>\n",
    " F1-Score is 32.89%.In 0-R, it's 0<br>\n",
    " Accuracy is not enough to evaluate, same with comparing NB with Zero-R, the performance of accuracy is really bad. But F1-Score could represent the performance of precision and recall. Precision and recall also show that the predict result is not so good.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4>**c) Compare the classifiers (Naive Bayes and K-NN) based on metricsâ€™ results. Provide a\n",
    "comparatory discussion on the results. [no programming required] (1 mark)**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3>The accuracy of Naive Bayes and K-NN is similiar, the result of F1-Score and accuracy is also closer. But KNN seems to have a higher predict performances on F1-Score and precision that are greater than those of NB classifier.<br>\n",
    "For example, the comparison in KNN vs CNB: <br>\n",
    "F1-Score: knn-32.89% vs cnb-28.50%<br>\n",
    "recall:  knn22.82% vs cnb-32.00%<br>\n",
    "precision:  knn58.73% vs cnb-25.69%<br>\n",
    "</font>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
